---
layout: post
title: Reacting to my ICER 2016 Reviews
date: 2016-06-27
tags:
  - ICER
---


## Introduction

What follows may contain [inside baseball](https://en.wikipedia.org/wiki/Inside_baseball_(metaphor)). I'm going to go review-by-review, point by point, for each of my 2 ICER submissions.

## Review 3

### Overall evaluation: **4**: (Borderline, lean to accept)

> The authors describe a case study (of one student) where they are trying to develop accounts of students' programming activity that explain the form and evolution of their code on a design project. They use ethnographic observation clinical interviewing, and code snapshot analysis to examine a student's design choices on a coding project.

That's certainly a fair summary.

### Discussion of related work: 4: (covers key related work; its relationship to submission is described, but could be extended further)

The reviewer didn't elaborate here. Also fine by me.

### Theoretical basis for the paper: **4**: (theoretical basis obvious, with some citations and argument for how it is applied in the research)

OK, Now I'm getting a bit curious. The reviewer gives us a 4 on both related work and theoretical basis, but thus far hasn't offered any specific observations of gaps. They also haven't suggested anything that could improve the paper.

### Use of Theory *(not a numeric category)*

> The authors cite various works that are related to their study. They motivate their work by explaining the current state of the world in the context of code snapshot review, and talk about the pros and cons of using this kind of data to interpret information about users and their needs.

I agree; we did those things.

### Research Methodology: **2** (questionable choice of research approach and methods)

OK, that's a low grade. The reviewer offers no comments here, so I guess we'll keep reading.

### Exposition of research methods: **2** (data collected and analyzed, but some aspects unclearly described)

There's no explanation here; it's just blank

### Discussion of results and conclusions: **3** (plausible interpretation of fidings)

### Methodology and Empirical Bias *(non-numerical)*

> Overall, it is very clear what the authors did in this study â€“ they analyzed the work Rebecca did for one of her projects using code snapshots and augmenting that information with interviews. The data is rich and well described.

Thanks!

> One concern the reviewer has is that this is a case study of *one* individual, so it is unclear how what we learned from Rebecca can generalize. However, the contribution of the paper is partly the method in which this study was conducted and demonstrating how it can be beneficial to use different sources of information to triangulate on interpretations and conclusions about a learners' coding process and issues they may have run into.

This reviewer has a concern about this being an "N=1" study. It's an unfortunately common concern for researchers like me who use case studies. My colleagues and I spent more than three years fighting "N=1" objections to get [our *Journal of Engineering Education* article](http://dx.doi.org/10.1002/jee.20035) accepted and into press. An exact quote from one of that article's reviews (the first of three rounds of reviews) then was,

> Problem with this paper is not the topic, but that N=1. I run into these students a lot, and there are differences among them, especially as to outcome (authors do not even have 1 outcome---it is unknown if the subject stays in engineering on not).



> Another concern is the (lack of ) description of how Rebecca was chosen to be the subject. According to the authors, there were 3 other students who participated in the study. What happened to their data? Why exactly was Rebecca chosen and not the others? One major concern is whether or not Rebecca is representative of other students. This leads to the question of whether the method described in the paper to analyze Rebecca's work and interview her would work with other students?

### Contribution and relevance to the international computing education research field

### Significance of contributions/results

### Writing and expression

### Suggestions regarding the writing or other comments

<table>
  <tr>
    <td>Overall Evaluation</td>
    <td>4 (Borderline, lean to accept)</td>
  </tr>
</table>
